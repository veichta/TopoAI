{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.upernet import UperNet\n",
    "from src.losses import Criterion\n",
    "from src.utils.io import load_image, load_mask\n",
    "\n",
    "model = UperNet(freeze_backbone=False)\n",
    "\n",
    "print(f\"Number of parameters: {model.n_trainable_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = torch.rand(2, 3, 400, 400)\n",
    "\n",
    "out = model(tens)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(\"../data/processed/validation/images/000000001_cil.jpg\") * 255\n",
    "mask = load_mask(\"../data/processed/validation/masks/000000001_cil.png\")\n",
    "\n",
    "img = img.astype(\"uint8\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tens = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float()\n",
    "out = model(img_tens)\n",
    "\n",
    "pred = out.detach().squeeze().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models.unet_pp import UNetPlus\n",
    "\n",
    "# model = UNetPlus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "args = {\n",
    "    'device': 'cpu',\n",
    "    'miou_weight': 1.0,\n",
    "    'bce_weight': 1.0,\n",
    "    'mse_weight': 1.0,\n",
    "    'focal_weight': 1.0,\n",
    "    'vec_weight': 0.1,\n",
    "    'edge_weight': 0,\n",
    "    'gaploss_weight': 0,\n",
    "    'soft_skeleton_iter': 5,\n",
    "    'alpha': 0.5,\n",
    "    'smoothing': 1.0,\n",
    "    'cl_dice_weight': 0,\n",
    "    'topo_weight': 0,\n",
    "    'topo_k0': 3,\n",
    "    'topo_k1': 3,\n",
    " }\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = Criterion(args)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"#params: {n_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tens = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float()\n",
    "gt_tens = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "weights_tens = torch.ones_like(gt_tens)\n",
    "img_tens.shape, gt_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pbar = tqdm(range(100), desc=\"Training\", ncols=80)\n",
    "\n",
    "for epoch in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    out = model(img_tens).squeeze(1)\n",
    "    loss = criterion(out, gt_tens, weights_tens)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        o = model(img_tens).squeeze(1)\n",
    "\n",
    "        p = o.squeeze().detach().sigmoid().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "        ax[0].imshow(img)\n",
    "        ax[1].imshow(p)\n",
    "        ax[2].imshow(mask)\n",
    "        plt.show()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(img_tens)\n",
    "\n",
    "loss = criterion(o, gt_tens, weights_tens)\n",
    "\n",
    "p = o.squeeze().detach().sigmoid().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(p)\n",
    "ax[2].imshow(mask)\n",
    "fig.suptitle(f\"Loss: {loss.item():.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
