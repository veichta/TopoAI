{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import Normalize\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.base_unet import BaseUNet\n",
    "from src.models.unet_pp import UNetPlus\n",
    "from src.utils.visualizations import plot_predictions\n",
    "from src.utils.io import load_image, save_mask\n",
    "from src.scripts.mask_to_submission import masks_to_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"../logs/2023-07-11_13-32-43\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_path = os.path.join(checkpoint, \"config.json\")\n",
    "with open(args_path, \"r\") as f:\n",
    "    vars = json.load(f)\n",
    "\n",
    "args = argparse.Namespace(**vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = os.path.join(\"..\", args.metadata)\n",
    "\n",
    "metadata = json.load(open(metadata, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == \"unet\":\n",
    "    model = BaseUNet()\n",
    "elif args.model == \"unet++\":\n",
    "    model = UNetPlus()\n",
    "else:\n",
    "    raise ValueError(\"Invalid model name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(checkpoint, \"best_model.pt\"), map_location=torch.device(\"cpu\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = \"../data/test/images/\"\n",
    "\n",
    "fnames = os.listdir(test_images)\n",
    "fnames = [os.path.join(test_images, fname) for fname in fnames if fname.endswith(\".png\")]\n",
    "\n",
    "len(fnames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_path = \"../data/preds/\"\n",
    "if not os.path.exists(pred_path):\n",
    "    os.makedirs(pred_path)\n",
    "\n",
    "mean = metadata[\"cil\"][\"img_mean\"]\n",
    "std = metadata[\"cil\"][\"img_std\"]\n",
    "\n",
    "transfrom = Normalize(mean=mean, std=std)\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for fname in tqdm(fnames, desc=\"Predicting\", total=len(fnames), ncols=80):\n",
    "        image = load_image(fname)\n",
    "        image = torch.tensor(image)\n",
    "        image = image.permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "        image = transfrom(image)\n",
    "\n",
    "        prediction = model(image).squeeze(0)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "\n",
    "        out_fname = os.path.join(pred_path, os.path.basename(fname))\n",
    "        pred = prediction.detach().numpy() > 0.5\n",
    "        pred = pred.astype(np.uint8) * 255\n",
    "        pred = np.stack([pred, pred, pred], axis=-1)\n",
    "        save_mask(pred, out_fname)\n",
    "\n",
    "predictions = torch.stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "# images = [torch.tensor(load_image(fname)) for fname in fnames[:N]]\n",
    "# masks = [torch.zeros_like(image) for image in predictions[:N]]\n",
    "# weights = [torch.zeros_like(image) for image in predictions[:N]]\n",
    "\n",
    "# images = torch.stack(images)\n",
    "# masks = torch.stack(masks)\n",
    "# weights = torch.stack(weights)\n",
    "\n",
    "plot_predictions(\n",
    "    images=images,\n",
    "    masks=masks,\n",
    "    predictions=predictions[:N],\n",
    "    weights=predictions[:N] > .5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = os.listdir(pred_path)\n",
    "fnames = [os.path.join(pred_path, fname) for fname in fnames if fname.endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_to_submission(\n",
    "    \"../data/submission.csv\",\n",
    "    \"\",\n",
    "    *sorted(fnames),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
